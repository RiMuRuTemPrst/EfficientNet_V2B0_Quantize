# T√™n file: dynamic_inference_and_detailed_log.py
import tensorflow as tf
import numpy as np
import os
import time

# ==============================================================================
# 0. C·∫§U H√åNH
# ==============================================================================
# Bu·ªôc ch·∫°y tr√™n CPU ƒë·ªÉ tr√°nh l·ªói driver v√† tƒÉng t√≠nh ·ªïn ƒë·ªãnh khi g·ª° l·ªói
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'

# ‚öôÔ∏è C·∫§U H√åNH ƒê√ÅNH GI√Å ‚öôÔ∏è
LOG_TENSORS_FOR_FIRST_IMAGE_ONLY = True
#   S·ªë l∆∞·ª£ng ·∫£nh ƒë·ªÉ ƒë√°nh gi√° 
NUM_IMAGES_TO_EVALUATE = 1000
# ‚öôÔ∏è C·∫§U H√åNH DYNAMIC FIXED-POINT ‚öôÔ∏è
QUANT_CONFIG = {
    # T√™n l·ªõp : {'ifm_m': In, 'w_m': Weight, 'ofm_m': Out}
    'stem_conv': {'ifm_m': 7, 'w_m': 7, 'ofm_m': 6},
    'block1_conv': {'ifm_m': 6, 'w_m': 7, 'ofm_m': 6},
    'block2a_expand': {'ifm_m': 6, 'w_m': 3, 'ofm_m': 4},
    'block2a_project': {'ifm_m': 4, 'w_m': 7, 'ofm_m': 3},
    'block2b_expand': {'ifm_m': 3, 'w_m': 5, 'ofm_m': 8},
    'block2b_project': {'ifm_m': 8, 'w_m': 6, 'ofm_m': 4},
    'block3a_expand': {'ifm_m': 4, 'w_m': 4, 'ofm_m': 3},
    'block3a_project': {'ifm_m': 3, 'w_m': 6, 'ofm_m': 5},
    'block3b_expand': {'ifm_m': 5, 'w_m': 5, 'ofm_m': 4},
    'block3b_project': {'ifm_m': 4, 'w_m': 6, 'ofm_m': 4},
    'dense_128': {'ifm_m': 4, 'w_m': 6, 'ofm_m': 5},
    'predictions': {'ifm_m': 5, 'w_m': 7, 'ofm_m': 5},
}
N_BITS = 8

# --- C√°c h√†m ti·ªán √≠ch ---
def quantize_dequantize(tensor_float, n_bits, m_frac_bits):
    scale = 2.0 ** m_frac_bits
    min_val, max_val = -2**(n_bits - 1), 2**(n_bits - 1) - 1
    quantized_values = np.clip(np.round(tensor_float * scale), min_val, max_val)
    return quantized_values.astype(np.float32) / scale

def requantize_dequantize_ofm(ofm_tensor_float, ifm_m_bits, weight_m_bits, ofm_m_bits, n_bits_out):
    in_total_m_bits = ifm_m_bits + weight_m_bits
    scale_in, scale_out = 2.0 ** in_total_m_bits, 2.0 ** ofm_m_bits
    shift_amount = in_total_m_bits - ofm_m_bits
    min_val, max_val = -2**(n_bits_out - 1), 2**(n_bits_out - 1) - 1
    intermediate_int = np.round(ofm_tensor_float * scale_in)
    if shift_amount > 0:
        requantized_int = np.round(intermediate_int / (2.0 ** shift_amount))
    else:
        requantized_int = np.round(intermediate_int * (2.0 ** -shift_amount))
    requantized_int_clipped = np.clip(requantized_int, min_val, max_val)
    return requantized_int_clipped.astype(np.float32) / scale_out

def save_tensor_to_txt(base_dir, layer_name, tensor_type, tensor):
    if tensor is None: return
    if hasattr(tensor, 'numpy'): tensor = tensor.numpy()
    if tensor.ndim == 4:
        tensor = np.transpose(tensor, (0, 3, 1, 2))
    os.makedirs(base_dir, exist_ok=True)
    filepath = os.path.join(base_dir, f"{layer_name}_{tensor_type}.txt")
    np.savetxt(filepath, tensor.flatten(), fmt='%.8f')


# ==============================================================================
# 1. T·∫¢I M√î H√åNH V√Ä D·ªÆ LI·ªÜU
# ==============================================================================
print("--- B∆Ø·ªöC 1: T·∫¢I M√î H√åNH V√Ä D·ªÆ LI·ªÜU ---")
LOG_DIR = 'inference_logs_detailed'
FLOAT_MODEL_FILE = 'cifar10_custom_hswish_trained.keras'

# ƒê·ªãnh nghƒ©a h√†m custom ƒë·ªÉ TensorFlow hi·ªÉu khi t·∫£i m√¥ h√¨nh
def custom_hard_swish(x):
    return x * tf.nn.relu6(x + 3) / 6

try:
    float_model = tf.keras.models.load_model(
        FLOAT_MODEL_FILE,
        custom_objects={'custom_hard_swish': custom_hard_swish}
    )
    print(f"‚úÖ ƒê√£ t·∫£i th√†nh c√¥ng m√¥ h√¨nh float32: {FLOAT_MODEL_FILE}")
except Exception as e:
    print(f"\n--- ‚ùå L·ªñI KHI T·∫¢I M√î H√åNH ---")
    print(f"Chi ti·∫øt l·ªói: {e}")
    print("Vui l√≤ng ƒë·∫£m b·∫£o file model ƒë√£ ƒë∆∞·ª£c t·∫°o ra t·ª´ script training v√† kh√¥ng b·ªã l·ªói.")
    print("--------------------------------\n")
    exit()

# B·ªè b∆∞·ªõc clone_model kh√¥ng c·∫ßn thi·∫øt v√† l·∫•y layer tr·ª±c ti·∫øp
print("L·∫•y th√¥ng tin c√°c layer t·ª´ m√¥ h√¨nh...")
layers_quant_config = {layer.name: layer for layer in float_model.layers}
layers_float = {layer.name: layer for layer in float_model.layers}

(_, _), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()


# ==============================================================================
# 2. H√ÄM X·ª¨ L√ù & V√íNG L·∫∂P ƒê√ÅNH GI√Å
# ==============================================================================
# THAY TH·∫æ H√ÄM C≈® B·∫∞NG H√ÄM N√ÄY
def process_and_log_layer_detailed(layer_name, x_quant_in, x_float_in, log_to_file=False):
    float_layer = layers_float[layer_name]
    quant_config_layer = layers_quant_config[layer_name]
    config = QUANT_CONFIG[layer_name]
    ifm_m, w_m, ofm_m = config['ifm_m'], config['w_m'], config['ofm_m']

    # Lu·ªìng Float32 ƒë·ªÉ so s√°nh
    x_float_out = float_layer(x_float_in)

    # Lu·ªìng Quantized (T√°i t·∫°o th·ªß c√¥ng)
    float_weights = float_layer.get_weights()
    quant_w_kernel = quantize_dequantize(float_weights[0], N_BITS, w_m)
    quant_w_bias = None
    if len(float_weights) > 1:
      quant_w_bias = quantize_dequantize(float_weights[1], N_BITS, ifm_m + w_m)

    quant_input_snapped = quantize_dequantize(x_quant_in, N_BITS, ifm_m)

    if isinstance(quant_config_layer, tf.keras.layers.Conv2D):
        strides, padding = quant_config_layer.strides, quant_config_layer.padding.upper()
        output_after_conv = tf.nn.conv2d(quant_input_snapped, quant_w_kernel, strides=strides, padding=padding)
    elif isinstance(quant_config_layer, tf.keras.layers.Dense):
        output_after_conv = tf.matmul(quant_input_snapped, quant_w_kernel)
    else:
        output_after_conv = quant_input_snapped

    output_after_bias = output_after_conv + quant_w_bias if quant_w_bias is not None else output_after_conv
    output_after_activation = quant_config_layer.activation(output_after_bias)

    is_final_dense = (layer_name == 'predictions')
    x_quant_out = output_after_activation if is_final_dense else \
        requantize_dequantize_ofm(output_after_activation, ifm_m, w_m, ofm_m, N_BITS)

    # Ghi log
    if log_to_file:
        quant_log_dir = os.path.join(LOG_DIR, 'quantized')
        # ‚úÖ TH√äM D√íNG N√ÄY: T·∫°o th∆∞ m·ª•c cho log float32
        float_log_dir = os.path.join(LOG_DIR, 'float32')

        print(f"\n--- Ghi log chi ti·∫øt cho ·∫£nh ƒë·∫ßu ti√™n, l·ªõp {layer_name} ---")

        # --- Ghi log cho lu·ªìng Quantized (gi·ªØ nguy√™n) ---
        save_tensor_to_txt(quant_log_dir, layer_name, 'input', quant_input_snapped)
        save_tensor_to_txt(quant_log_dir, layer_name, 'weight', quant_w_kernel)
        if quant_w_bias is not None:
          save_tensor_to_txt(quant_log_dir, layer_name, 'bias', quant_w_bias)
        # ƒê·ªïi t√™n file output ƒë·ªÉ ƒë·ªìng nh·∫•t
        save_tensor_to_txt(quant_log_dir, layer_name, 'output', x_quant_out)

        # ‚úÖ TH√äM KH·ªêI L·ªÜNH N√ÄY: Ghi log cho lu·ªìng Float32 ---
        save_tensor_to_txt(float_log_dir, layer_name, 'input', x_float_in)
        save_tensor_to_txt(float_log_dir, layer_name, 'weight', float_weights[0])
        if len(float_weights) > 1:
          save_tensor_to_txt(float_log_dir, layer_name, 'bias', float_weights[1])
        save_tensor_to_txt(float_log_dir, layer_name, 'output', x_float_out)

    return x_quant_out, x_float_out

# V√≤ng l·∫∑p ƒë√°nh gi√° ch√≠nh
print(f"\n--- B∆Ø·ªöC 2: B·∫ÆT ƒê·∫¶U ƒê√ÅNH GI√Å TR√äN {NUM_IMAGES_TO_EVALUATE} ·∫¢NH ---")
correct_float, correct_quant = 0, 0
start_time = time.time()

for i in range(NUM_IMAGES_TO_EVALUATE):
    print(f"\rƒêang x·ª≠ l√Ω ·∫£nh {i + 1}/{NUM_IMAGES_TO_EVALUATE}...", end="")
    sample_image, true_label_index = x_test[i:i+1], y_test[i][0]
    x_input = tf.image.resize(sample_image, (224, 224))
    should_log = (i == 0 and LOG_TENSORS_FOR_FIRST_IMAGE_ONLY)

    # --- B·∫Øt ƒë·∫ßu lu·ªìng inference tu·∫ßn t·ª± cho 1 ·∫£nh ---
    x_quant, x_float = x_input, x_input
    x_quant, x_float = layers_quant_config['rescaling'](x_quant), layers_float['rescaling'](x_float)
    x_quant, x_float = process_and_log_layer_detailed('stem_conv', x_quant, x_float, should_log)
    x_quant, x_float = process_and_log_layer_detailed('block1_conv', x_quant, x_float, should_log)
    x_quant, x_float = process_and_log_layer_detailed('block2a_expand', x_quant, x_float, should_log)
    x_quant, x_float = process_and_log_layer_detailed('block2a_project', x_quant, x_float, should_log)
    x_skip_2b_quant, x_skip_2b_float = x_quant, x_float
    x_quant, x_float = process_and_log_layer_detailed('block2b_expand', x_quant, x_float, should_log)
    x_quant, x_float = process_and_log_layer_detailed('block2b_project', x_quant, x_float, should_log)

    x_quant = layers_quant_config['block2b_drop'](x_quant, training=False)
    x_float = layers_float['block2b_drop'](x_float, training=False)
    
    x_quant, x_float = layers_quant_config['block2b_add']([x_quant, x_skip_2b_quant]), layers_float['block2b_add']([x_float, x_skip_2b_float])
    x_quant, x_float = process_and_log_layer_detailed('block3a_expand', x_quant, x_float, should_log)
    x_quant, x_float = process_and_log_layer_detailed('block3a_project', x_quant, x_float, should_log)
    x_skip_3b_quant, x_skip_3b_float = x_quant, x_float
    x_quant, x_float = process_and_log_layer_detailed('block3b_expand', x_quant, x_float, should_log)
    x_quant, x_float = process_and_log_layer_detailed('block3b_project', x_quant, x_float, should_log)

    x_quant = layers_quant_config['block3b_drop'](x_quant, training=False)
    x_float = layers_float['block3b_drop'](x_float, training=False)

    x_quant, x_float = layers_quant_config['block3b_add']([x_quant, x_skip_3b_quant]), layers_float['block3b_add']([x_float, x_skip_3b_float])
    x_quant, x_float = layers_quant_config['global_avg_pool'](x_quant), layers_float['global_avg_pool'](x_float)
    x_quant, x_float = process_and_log_layer_detailed('dense_128', x_quant, x_float, should_log)

    x_quant = layers_quant_config['dropout_final'](x_quant, training=False)
    x_float = layers_float['dropout_final'](x_float, training=False)

    final_logits_quant, final_logits_float = process_and_log_layer_detailed('predictions', x_quant, x_float, should_log)

    if np.argmax(tf.nn.softmax(final_logits_float)) == true_label_index: correct_float += 1
    if np.argmax(tf.nn.softmax(final_logits_quant)) == true_label_index: correct_quant += 1

end_time = time.time()
print(f"\nƒê√°nh gi√° ho√†n t·∫•t. T·ªïng th·ªùi gian: {end_time - start_time:.2f} gi√¢y.")


# ==============================================================================
# 3. HI·ªÇN TH·ªä K·∫æT QU·∫¢ ƒê·ªò CH√çNH X√ÅC
# ==============================================================================
print("\n--- B∆Ø·ªöC 3: K·∫æT QU·∫¢ ƒê·ªò CH√çNH X√ÅC ---")
acc_float = (correct_float / NUM_IMAGES_TO_EVALUATE) * 100
acc_quant = (correct_quant / NUM_IMAGES_TO_EVALUATE) * 100
acc_drop = acc_float - acc_quant

print(f"S·ªë l∆∞·ª£ng ·∫£nh ƒë√°nh gi√°: {NUM_IMAGES_TO_EVALUATE}")
print("-" * 50)
print(f"‚úÖ ƒê·ªô ch√≠nh x√°c m√¥ h√¨nh Float32: {acc_float:.2f}% ({correct_float}/{NUM_IMAGES_TO_EVALUATE})")
print(f"‚öôÔ∏è ƒê·ªô ch√≠nh x√°c m√¥ h√¨nh Quantized: {acc_quant:.2f}% ({correct_quant}/{NUM_IMAGES_TO_EVALUATE})")
print("-" * 50)
print(f"üìâ ƒê·ªô s·ª•t gi·∫£m ch√≠nh x√°c: {acc_drop:.2f}%")